{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T10:46:46.295697Z",
     "iopub.status.busy": "2025-01-29T10:46:46.295456Z",
     "iopub.status.idle": "2025-01-29T10:46:56.465186Z",
     "shell.execute_reply": "2025-01-29T10:46:56.464306Z",
     "shell.execute_reply.started": "2025-01-29T10:46:46.295675Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import nltk\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "\n",
    "import PyPDF2\n",
    "import google.generativeai as genai\n",
    "\n",
    "import chromadb\n",
    "from IPython.display import Markdown\n",
    "\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T10:46:56.467268Z",
     "iopub.status.busy": "2025-01-29T10:46:56.466836Z",
     "iopub.status.idle": "2025-01-29T10:46:56.487492Z",
     "shell.execute_reply": "2025-01-29T10:46:56.486707Z",
     "shell.execute_reply.started": "2025-01-29T10:46:56.467246Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "nltk.download('punkt_tab')\n",
    "nltk.download('averaged_perceptron_tagger_eng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T12:25:46.275409Z",
     "iopub.status.busy": "2025-01-29T12:25:46.275085Z",
     "iopub.status.idle": "2025-01-29T12:25:46.279461Z",
     "shell.execute_reply": "2025-01-29T12:25:46.278549Z",
     "shell.execute_reply.started": "2025-01-29T12:25:46.275379Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "RAG_SYSTEM_PROMPT = \"\"\"You are a helpful assistant. You will receive a context and a question. Your task is to generate a complete answer based only on the provided context.\n",
    "\n",
    "The context may contain image references in the format:\n",
    "![image-description-here](image-path-here)\n",
    "When generating your response, you must properly format images in Markdown like this:\n",
    "![image-description-here](image-path-here)\n",
    "\n",
    "Your response must be in Markdown to ensure images display correctly.\n",
    "\n",
    "If the context does not have enough information to answer the question, respond with:\n",
    "\"The given documents do not contain the required information.\"\n",
    "\n",
    "Examples:\n",
    "Example 1:\n",
    "Context:\n",
    "\"The Eiffel Tower is a famous landmark in Paris. ![A beautiful view of the Eiffel Tower](eiffel.jpg).\"\n",
    "\n",
    "Question:\n",
    "\"Where is the Eiffel Tower located?\"\n",
    "\n",
    "Response:\n",
    "\"![A beautiful view of the Eiffel Tower](eiffel.jpg) \\n\\nThe Eiffel Tower is located in Paris.\"\n",
    "\n",
    "Example 2:\n",
    "Context:\n",
    "\"Mars is known as the Red Planet due to its reddish appearance.\"\n",
    "\n",
    "Question:\n",
    "\"What color is Mars?\"\n",
    "\n",
    "Response:\n",
    "\"Mars is known as the Red Planet due to its reddish appearance.\"\n",
    "\n",
    "Example 3:\n",
    "Context:\n",
    "\"An ear, nose, and throat doctor (ENT) specializes in everything having to do with those parts of the body.\"\n",
    "\n",
    "Question:\n",
    "\"Who discovered gravity?\"\n",
    "\n",
    "Response:\n",
    "\"The given documents do not contain the required information.\"\n",
    "\"\"\"\n",
    "\n",
    "IMAGE_SYSTEM_PROMPT = \"Given an image, you need to generate a summary that describes the image precisely. You need to ensure all details are covered and the summary is concise and clear.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T12:26:59.875946Z",
     "iopub.status.busy": "2025-01-29T12:26:59.875533Z",
     "iopub.status.idle": "2025-01-29T12:26:59.896942Z",
     "shell.execute_reply": "2025-01-29T12:26:59.895854Z",
     "shell.execute_reply.started": "2025-01-29T12:26:59.875910Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class MultimodalRag:\n",
    "    def __init__(self, api_key, collection_name, db_path=\"./chroma_db\"):\n",
    "        self.api_key = api_key\n",
    "        self.client = chromadb.PersistentClient(path=db_path)\n",
    "        self.collection_name = collection_name\n",
    "        \n",
    "        genai.configure(api_key=self.api_key)\n",
    "        self.generation_config = {\n",
    "            \"temperature\": 1,\n",
    "            \"top_p\": 0.95,\n",
    "            \"top_k\": 40,\n",
    "            \"max_output_tokens\": 8192,\n",
    "            \"response_mime_type\": \"text/plain\",\n",
    "        }\n",
    "\n",
    "        self.rag_model = genai.GenerativeModel(\n",
    "            model_name=\"gemini-2.0-flash-exp\",\n",
    "            generation_config=self.generation_config,\n",
    "            system_instruction=RAG_SYSTEM_PROMPT\n",
    "        )\n",
    "\n",
    "        self.image_model = genai.GenerativeModel(\n",
    "            model_name=\"gemini-2.0-flash-exp\",\n",
    "            generation_config=self.generation_config,\n",
    "            system_instruction=IMAGE_SYSTEM_PROMPT\n",
    "        )\n",
    "\n",
    "    def delete_collection(self):\n",
    "        self.client.delete_collection(self.collection_name)\n",
    "    \n",
    "    def upload_to_gemini(self, path, mime_type=None):\n",
    "        return genai.upload_file(path, mime_type=mime_type)\n",
    "    \n",
    "    def summarise_image(self, image_path):\n",
    "        file = self.upload_to_gemini(image_path, mime_type=\"image/jpeg\")\n",
    "        chat_session = self.image_model.start_chat(history=[{\"role\": \"user\", \"parts\": [file]}])\n",
    "        response = chat_session.send_message(\"Analyze the provided image and generate a concise, detailed summary.\")\n",
    "        return response.text\n",
    "\n",
    "    def parse_pdf(self, pdf_path):\n",
    "        parsed_pdf = partition_pdf(pdf_path, extract_images_in_pdf=True, infer_table_structure=True, max_characters=4000, new_after_n_chars=3800, combine_text_under_n_chars=2000)\n",
    "        return parsed_pdf\n",
    "\n",
    "    def replace_image_with_summary(self, parsed_pdf):\n",
    "        data_to_embed = []\n",
    "\n",
    "        for parsed_object in parsed_pdf:\n",
    "            parsed_object = parsed_object.to_dict()\n",
    "            if parsed_object['type'] == \"Image\":\n",
    "                parsed_object['image_summary'] = self.summarise_image(parsed_object['metadata']['image_path'])\n",
    "            data_to_embed.append(parsed_object)\n",
    "        \n",
    "        return data_to_embed\n",
    "\n",
    "    def group_data_by_page(self, data_to_embed):\n",
    "        data_by_page = [[]]\n",
    "        cur_page_number = 1\n",
    "        \n",
    "        for data in data_to_embed:\n",
    "            if data['type'] == 'Footer':\n",
    "                continue\n",
    "            if data['metadata']['page_number'] != cur_page_number:\n",
    "                cur_page_number += 1\n",
    "                data_by_page.append([])\n",
    "            data_by_page[-1].append(data)\n",
    "        \n",
    "        return data_by_page\n",
    "    \n",
    "    def create_chunks(self, data_by_page):\n",
    "        chunks = []\n",
    "        for page in data_by_page:\n",
    "            chunk_text = []\n",
    "            for data in page:\n",
    "                if data['type'] == \"Image\":\n",
    "                    image_path = data['metadata']['image_path']\n",
    "                    relative_image_path = image_path.replace(os.getcwd(), \".\")\n",
    "                    text = f\"![{data['image_summary']}]({relative_image_path})\"\n",
    "                else:\n",
    "                    text = data['text']\n",
    "                chunk_text.append(text)\n",
    "            chunks.append(\"\\n\".join(chunk_text))\n",
    "        return chunks\n",
    "        \n",
    "    def process_pdf(self, pdf_path):\n",
    "        print(\"0% processing done. Parsing PDF\")\n",
    "        parsed_pdf = self.parse_pdf(pdf_path)\n",
    "        print(\"40% processing done. Replacing Images with Summaries\")\n",
    "        data_to_embed = self.replace_image_with_summary(parsed_pdf) \n",
    "        print(\"75% processing done. Creating Chunks\")\n",
    "        data_by_page = self.group_data_by_page(data_to_embed)\n",
    "        chunks = self.create_chunks(data_by_page)\n",
    "        return chunks\n",
    "    \n",
    "    def get_query_embedding(self, query):\n",
    "        result = genai.embed_content(model=\"models/text-embedding-004\", content=query)\n",
    "        return result['embedding']\n",
    "\n",
    "    def ingest_pdf(self, pdf_path):\n",
    "        chunks = self.process_pdf(pdf_path)\n",
    "        print(\"80% processing done. Creating Embeddings\")\n",
    "        collection = self.client.get_or_create_collection(name=self.collection_name)\n",
    "        embeddings = [self.get_query_embedding(chunk) for chunk in chunks]\n",
    "        collection.add(\n",
    "            ids=[f\"doc_{i}\" for i in range(len(chunks))],\n",
    "            documents=chunks,\n",
    "            embeddings=embeddings,\n",
    "            metadatas=[{\"page_number\": index+1} for index in range(len(chunks))]\n",
    "        )\n",
    "        print(\"100% processing done. PDF ingested successfully\")\n",
    "        \n",
    "    \n",
    "    def retrieve_similar_documents(self, query_text, top_k=3):\n",
    "        collection = self.client.get_collection(name=self.collection_name)\n",
    "        query_embedding = self.get_query_embedding(query_text)\n",
    "        results = collection.query(query_embeddings=[query_embedding], n_results=top_k)\n",
    "        return [doc for doc in results['documents'][0]]\n",
    "    \n",
    "    def prompt_builder(self, context, question):\n",
    "        return f\"\"\"Find the context below:\n",
    "        \n",
    "        Context:\n",
    "        \n",
    "        {context}\n",
    "        \n",
    "        Question: {question}\n",
    "        \"\"\"\n",
    "    \n",
    "    def invoke(self, question):\n",
    "        context = self.retrieve_similar_documents(question)\n",
    "        chat_session = self.rag_model.start_chat()\n",
    "        prompt = self.prompt_builder(context, question)\n",
    "        response = chat_session.send_message(prompt)\n",
    "        return response.parts[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T12:27:00.334427Z",
     "iopub.status.busy": "2025-01-29T12:27:00.334040Z",
     "iopub.status.idle": "2025-01-29T12:27:00.343998Z",
     "shell.execute_reply": "2025-01-29T12:27:00.343033Z",
     "shell.execute_reply.started": "2025-01-29T12:27:00.334395Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "gemini_rag = MultimodalRag(os.getenv('GEMINI_API_KEY'), \"attention_sample_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T12:27:01.934301Z",
     "iopub.status.busy": "2025-01-29T12:27:01.933974Z",
     "iopub.status.idle": "2025-01-29T12:27:24.401024Z",
     "shell.execute_reply": "2025-01-29T12:27:24.399933Z",
     "shell.execute_reply.started": "2025-01-29T12:27:01.934269Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "gemini_rag.ingest_pdf(\"test.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T12:27:24.402775Z",
     "iopub.status.busy": "2025-01-29T12:27:24.402407Z",
     "iopub.status.idle": "2025-01-29T12:27:29.155999Z",
     "shell.execute_reply": "2025-01-29T12:27:29.155033Z",
     "shell.execute_reply.started": "2025-01-29T12:27:24.402737Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "response = gemini_rag.invoke(\"Explain Encoder decoder with images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T12:27:29.157916Z",
     "iopub.status.busy": "2025-01-29T12:27:29.157569Z",
     "iopub.status.idle": "2025-01-29T12:27:29.163334Z",
     "shell.execute_reply": "2025-01-29T12:27:29.162304Z",
     "shell.execute_reply.started": "2025-01-29T12:27:29.157879Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "Markdown(response)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30840,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
